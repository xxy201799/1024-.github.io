<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/1024-xy.github.io/2019/11/09/hello-world-2/"/>
      <url>/1024-xy.github.io/2019/11/09/hello-world-2/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>分布式中间件</title>
      <link href="/1024-xy.github.io/2019/11/01/zookeeper-gong-zuo-yuan-li-yu-ying-yong-2/"/>
      <url>/1024-xy.github.io/2019/11/01/zookeeper-gong-zuo-yuan-li-yu-ying-yong-2/</url>
      
        <content type="html"><![CDATA[<h1 id="zookeeper分布式原理与应用"><a href="#zookeeper分布式原理与应用" class="headerlink" title="zookeeper分布式原理与应用"></a>zookeeper分布式原理与应用</h1><h3 id="场景一"><a href="#场景一" class="headerlink" title="场景一"></a>场景一</h3><hr><p>&emsp;&emsp;假设我们有20个搜索引擎的服务器（每个负责总索引中的一部分搜索任务）和一个总服务器（负责向这20个搜索引擎的服务器发出搜索请求并合并 结果集），一个备用的总服务器（负责总服务器宕机时替换总服务器），一个web cli（向总服务器发出搜索请求）。搜索引擎的服务器中的15个服务器现在提供搜索服务，5个服务器正在生成索引。这20个搜索引擎的服务器经常要让正在 提供搜索服务的服务器停止提供服务开始生成索引,或生成索引的服务器已经把索引生成完成可以搜索提供服务了.使用Zookeeper可以保证总服务器自动 感知有多少提供搜索引擎的服务器并向这些服务器发出搜索请求,备用的总服务器宕机时自动启用备用的总服务器,web的cgi能够自动地获知总服务器的网络地址变化.这些又如何做到呢?   </p><ol><li>提供搜索引擎的服务器都在Zookeeper中创建znode,zk.create(“/search/nodes/node1”,</li></ol><p>“hostname”.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateFlags.EPHEMERAL);</p><ol start="2"><li><p>总服务器可以从Zookeeper中获取一个znode的子节点的列表,zk.getChildren(“/search/nodes”, true);</p></li><li><p>总服务器遍历这些子节点,并获取子节点的数据生成提供搜索引擎的服务器列表.</p></li><li><p>当总服务器接收到子节点改变的事件信息,重新返回第二步.</p></li><li><p>总服务器在Zookeeper中创建节点,zk.create(“/search/master”, “hostname”.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateFlags.EPHEMERAL);</p></li><li><p>备用的总服务器监控Zookeeper中的”/search/master”节点.当这个znode的节点数据改变时,把自己启动变成总服务器,并把自己的网络地址数据放进这个节点.</p></li><li><p>web的cgi从Zookeeper中”/search/master”节点获取总服务器的网络地址数据并向其发送搜索请求.</p></li><li><p>web的cgi监控Zookeeper中的”/search/master”节点,当这个znode的节点数据改变时,从这个节点获取总服务器的网络地址数据,并改变当前的总服务器的网络地址.  </p></li></ol><h3 id="Zookeeper的功能有哪些"><a href="#Zookeeper的功能有哪些" class="headerlink" title="Zookeeper的功能有哪些"></a>Zookeeper的功能有哪些</h3><hr><h4 id="1、文件系统"><a href="#1、文件系统" class="headerlink" title="1、文件系统"></a>1、文件系统</h4><p>zookeeper维护了一个类似文件系统的数据结构：<br><img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213344_45.png" alt="zookeeper图片"><br>&emsp;&emsp;每个子目录项以及其下的子节点都是一个znode，我们能对这些znodes进行增删查改的操作，并且能够存储数据。<br>有四种类型的znode:  </p><p>1、PERSISTENT-持久化目录节点</p><p>客户端与zookeeper断开连接后，该节点依旧存在</p><p>2、 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点</p><p>客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号</p><p>3、EPHEMERAL-临时目录节点</p><p>客户端与zookeeper断开连接后，该节点被删除</p><p>4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点</p><p>客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号  </p><h4 id="2、通知机制"><a href="#2、通知机制" class="headerlink" title="2、通知机制"></a>2、通知机制</h4><p>&emsp;&emsp;客户端注册监听它关心的目录节点，一旦发生变化（数据变化，删除，子目录增加）时，zookeeper节点会通知客户端。  </p><h3 id="Zookeeper的可以用来做什么？"><a href="#Zookeeper的可以用来做什么？" class="headerlink" title="Zookeeper的可以用来做什么？"></a>Zookeeper的可以用来做什么？</h3><hr><h4 id="1、服务注册与发现"><a href="#1、服务注册与发现" class="headerlink" title="1、服务注册与发现"></a>1、服务注册与发现</h4><p>使用doubbo、kafuka等rpc框架进行对象以及数据的传输，在这个过程中，可以使用zookeeper进行服务的注册以及订阅，rpc框架在zoookeeper发布服务的地址，方法，类名。同样的rpcc框架的客户端在zookeeper监听该服务是否存在，然后拿到服务的地址，与rpc框架的服务端进行对象的传输。如果含有多个相同服务，则可以进行权重配比。</p><h4 id="2、配置中心"><a href="#2、配置中心" class="headerlink" title="2、配置中心"></a>2、配置中心</h4><p>所有程序都免不了配置，当你去要做一些开关去开启或者关闭某些功能的时候，以及一些服务器的配置，都可以放入zookeeper的某个节点目录中进行统一管理，当配置信息被改变将会通知各个客户端，更改其服务器配置。<br><img src="https://www.aboutyun.com/data/attachment/forum/201608/20/184509blnln2a7n5qqa95s.png" alt="zookeeper配置中心"></p><h4 id="3、zookeeper集群管理"><a href="#3、zookeeper集群管理" class="headerlink" title="3、zookeeper集群管理"></a>3、zookeeper集群管理</h4><p>zookeeper对于集群的管理就两点：是否有加入新的节点，和选举master。<br>对于第一点：所有机器约定在主节点上的GroupMembers下创建临时目录节点，然后监听父目录的子节点变化消息，一旦有机器挂掉，则临时节点删除，其他机器收到通知。当然新机器也是类似，对于第二点，每次选举最小编号的机器作为主节点就好<br><img src="http://www.aboutyun.com/data/attachment/forum/201608/20/184530b6abmegbk09ffgva.png" alt="zookeeper配置"></p><h4 id="4、zookeeper分布式锁"><a href="#4、zookeeper分布式锁" class="headerlink" title="4、zookeeper分布式锁"></a>4、zookeeper分布式锁</h4><p>zookeeper有两种分布式锁，一种保持独占，一种控制时序。<br>对于第一类，我们将一个临时znode看所一把锁，客户端尝试建立该节点，建立成功的拿到锁，获取资源。创建失败的则进行等待，对于第二类，则在其一个目录节点下面创建多个顺序节点，如果是读，前面几个节点都是读操作，则可以同时拿到资源，如果都是写，则进行独占。  </p><p><img src="http://www.aboutyun.com/data/attachment/forum/201608/20/184557iv77xzbyas7bc99o.png" alt="分布式锁"></p><h4 id="5、队列管理功能"><a href="#5、队列管理功能" class="headerlink" title="5、队列管理功能"></a>5、队列管理功能</h4><ol><li>同步队列<br>&emsp;&emsp;当一个对列成员都到达，这个队列才被视为可用队列。其具体实现为：在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 </li><li>队列按照FIFO方式进行入队和出队操作。<br>&emsp;&emsp;和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。  </li></ol><h3 id="分布式的数据与复制"><a href="#分布式的数据与复制" class="headerlink" title="分布式的数据与复制"></a>分布式的数据与复制</h3><p>Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：<br>1、容错<br>一个节点出错，不至于整个系统崩溃，别的节点可以接管他的工作。<br>2、提高性能<br>让客户端本地访问就近的节点，提高用户访问速度。  </p><h3 id="数据一致性与paxos算法"><a href="#数据一致性与paxos算法" class="headerlink" title="数据一致性与paxos算法"></a>数据一致性与paxos算法</h3><p> 据说Paxos算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据的一致性，这里有个原则就是：  </p><p> 在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。<br> Paxos算法解决的什么问题呢，解决的就是保证每个节点执行相同的操作序列。好吧，这还不简单，master维护一个全局写队列，所有写操作都必须放入这个队列编号，那么无论我们写多少个节点，只要写操作是按编号来的，就能保证一致性。</p><p> 没错，就是这样，可是如果master挂了呢。Paxos算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排序。编号严格递增，当一个节点接受了一个编号为100的写操作，之后又接受到编号为99的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总2n+1台，除非挂掉大于n台）。</p><h3 id="Zookeeper的工作原理（ZAB协议）"><a href="#Zookeeper的工作原理（ZAB协议）" class="headerlink" title="Zookeeper的工作原理（ZAB协议）"></a>Zookeeper的工作原理（ZAB协议）</h3><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p> zookeeper中的角色主要有以下三类，如下表所示：  </p><p> <img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213346_932.png" alt="角色"><br> 系统模型如图所示：<br> <img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213346_540.jpg" alt="zookeeper系统模型">  </p><h4 id="设计目的"><a href="#设计目的" class="headerlink" title="设计目的"></a>设计目的</h4><ol><li>最终一致性：client端不论连接到哪个server,展示给他的都是同一视图以及同一数据，这是zookeeper最重要的功能。</li><li>可靠性：zookeeper具有简单、健壮、良好的性能，如果消息m被一台服务器接受，那么它将被所有的服务器接受。</li><li>实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客 户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</li><li>等待无关性：慢的或者失效的client端的请求不得干预快速的client端的请求，使得每个client都能有效的等待。</li><li>原子性：更新数据或者节点只能成功或者失败。</li><li>顺序性：全局有序性是指如果一台服务器上的消息a在消息b之前发布，则所有服务器上的消息发布都要保持该顺序。<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分 别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的 状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系 统状态。<br>为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</li></ol><p>每个Server在工作过程中有三种状态：</p><p>LOOKING：当前Server不知道leader是谁，正在搜寻<br>LEADING：当前Server即为选举出来的leader<br>FOLLOWING：leader已经选举出来，当前Server与之同步</p><h5 id="选主流程"><a href="#选主流程" class="headerlink" title="选主流程"></a>选主流程</h5><hr><p>当leader崩溃或者失去大部分follower,这时候zk进入恢复模式，恢复模式重新选举出一个新的master,让所有的server恢复到一个正确的状态。zk的选举算法有两种：一种基于basic paxos算法实现，另一种基于fast paxos算法实现。系统默认选举算法为fast paxos算法。先介绍basic paxos流程：  1. 选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</p><ol start="2"><li><p>选举线程首先向所有Server发起一次询问(包括自己)；</p></li><li><p>选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(        id,zxid)，并将这些信息存储到当次选举的投票记录表中；</p></li><li><p>收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</p></li><li><p>线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。</p></li></ol><p>&emsp;&emsp;通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</p><p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：  </p><p><img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213346_59.png" alt="basic paxos"><br> fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：<br> <img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213346_900.png" alt="fast paxos">  </p><h5 id="同步流程"><a href="#同步流程" class="headerlink" title="同步流程"></a>同步流程</h5><hr><p> 选完leader以后，zk就进入状态同步过程。</p><ol><li><p>leader等待server连接；</p><p>2 .Follower连接leader，将最大的zxid发送给leader；</p><p>3 .Leader根据follower的zxid确定同步点；</p><p>4 .完成同步后通知follower 已经成为uptodate状态；</p><p>5 .Follower收到uptodate消息后，又可以重新接受client的请求进务了。<br><img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213347_647.jpg" alt="同步流程">  </p><h5 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h5><h6 id="Leader工作流程"><a href="#Leader工作流程" class="headerlink" title="Leader工作流程"></a>Leader工作流程</h6><p>Leader主要有三个功能：</p><p>1 .恢复数据；</p><p>2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</p><p>3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。</p><p>PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议息，包括写请求及同步请求；ACK消息是Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。  </p></li></ol><p><img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213347_829.png" alt="leader流程">  </p><h6 id="follower工作流程"><a href="#follower工作流程" class="headerlink" title="follower工作流程"></a>follower工作流程</h6><p>Follower主要有四个功能：</p><pre><code>1. 向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；2 .接收Leader消息并进行处理；3 .接收Client的请求，如果为写请求，发送给Leader进行投票；4 .返回Client结果。</code></pre><p>Follower的消息循环处理如下几种来自Leader的消息：</p><pre><code>1 .PING消息： 心跳消息；2 .PROPOSAL消息：Leader发起的提案，要求Follower投票；3 .COMMIT消息：服务器端最新一次提案的信息；4 .UPTODATE消息：表明同步完成；5 .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；6 .SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。</code></pre><p>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。  </p><p><img src="http://static.open-open.com/lib/uploadImg/20141108/20141108213347_577.png" alt="follower"></p><h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><p> <a href="https://blog.csdn.net/lingbo229/article/details/81052078" target="_blank" rel="noopener">https://blog.csdn.net/lingbo229/article/details/81052078</a><br> <a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">http://zookeeper.apache.org/</a><br> <a href="http://blog.csdn.net/cutesource/article/details/5822459" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/5822459</a><br> <a href="http://blog.csdn.net/pwlazy/article/details/8080626" target="_blank" rel="noopener">http://blog.csdn.net/pwlazy/article/details/8080626</a><br> <a href="http://nileader.blog.51cto.com/1381108/795265" target="_blank" rel="noopener">http://nileader.blog.51cto.com/1381108/795265</a><br> <a href="http://nileader.blog.51cto.com/1381108/926753" target="_blank" rel="noopener">http://nileader.blog.51cto.com/1381108/926753</a><br> <a href="http://nileader.blog.51cto.com/1381108/795230" target="_blank" rel="noopener">http://nileader.blog.51cto.com/1381108/795230</a><br> <a href="http://netcome.iteye.com/blog/1474255" target="_blank" rel="noopener">http://netcome.iteye.com/blog/1474255</a></p>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_Callable&amp;Future</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-callable-future-1/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-callable-future-1/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-Callable-amp-Future"><a href="#并发编程-Callable-amp-Future" class="headerlink" title="并发编程_Callable&amp;Future"></a>并发编程_Callable&amp;Future</h1>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_线程安全</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-java-nei-cun-mo-xing-2/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-java-nei-cun-mo-xing-2/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-线程安全"><a href="#并发编程-线程安全" class="headerlink" title="并发编程_线程安全"></a>并发编程_线程安全</h1><h2 id="什么是线程安全性？"><a href="#什么是线程安全性？" class="headerlink" title="什么是线程安全性？"></a>什么是线程安全性？</h2><p>可以被多个程序调用，并且调用没有共享内存中同一变量的交互，并且不需要使用任何操作来保证线程安全，同时得到的结果跟预期是正确的。那么我们称这个程序线程安全。<br><strong>示例</strong>：<br>线程安全</p><pre><code>public void count(){    int count = 0;    count++;}</code></pre><p>非线程安全</p><pre><code>int count = 0;public void count(){    count++;}</code></pre><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>我们在向无状态的对象中加入一个状态将会破坏他的线程安全如：  </p><pre><code>int count = 0;public void count(){    count++;}</code></pre><p>该count非线程安全，看似count++是个原子操作，其实cpu对它进行了从cpu缓存中读取，+1，写入缓存的操作。假如同时两个线程执行该方法，如果第一个线程在同一个时间拿到这个count并且都看到是9，同时+1写入缓存中，你将不会得到11，而是错误的10。</p><h3 id="竞争条件"><a href="#竞争条件" class="headerlink" title="竞争条件"></a>竞争条件</h3><p>使用潜在的过期观察值来决策或执行计算，这种竞争条件被称为<strong>检查在运行</strong>，你观察到一些一些事情为真，然后基于你的观察去执行一些动作：但事实上，从你观察再执行的期间，观察结果已经无效，从而引发错误修改。</p><h4 id="惰性初始化竞争条件"><a href="#惰性初始化竞争条件" class="headerlink" title="惰性初始化竞争条件"></a>惰性初始化竞争条件</h4><p>懒汉式单例模式就是一个很明显的例子(<strong>Dont do this</strong>)：</p><pre><code>public class LazyInitRace{    private ExpensiveObject instance = null;    public ExpensiveObject getInstance(){        if(instance == null){            instance = new ExpensiveObject();        }        return instance;    }}</code></pre><h3 id="复合操作"><a href="#复合操作" class="headerlink" title="复合操作"></a>复合操作</h3><p>前面说到的懒汉式单例以及count++都是非线程安全的，如何解决线程安全呢？为了避免竞争条件，必须阻止其他线程访问我们正在修改的变量，让我们可以确保：其他的线程想要查看和修改这一状态时，必须在我们线程开始之前或者之后。我们可以使用线程安全类来实现count++的安全问题。</p><pre><code>private final AtomicLong count = new AtomicLong (0);public void count(){    //对count进行自增操作    count.incrementAndGet();}</code></pre><p>java.util.concurrent.atomic包中包括了原子变量类，而这些对数值的操作都可以看做是原子操作。</p><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>通过线程安全的对象来管理类中非安全的状态，可以维护线程的安全性，但这样我们只能加入一种状态，但我们想要加入更多状态，可以仅仅加入更多线程安全的变量吗？</p><pre><code>private final AtomicReference&lt;Integer&gt; lastNumber = new AtomicReference&lt;Integer&gt;();private final AtomicReference&lt;Integer&gt; lastFactor = new AtomicReference&lt;Integer&gt;();public void service(){    Integer i = exec();    //存在竞争条件，不安全    Integer[] factorys  = factory[i]     lastNumber.set(i);    lastFactory.set(factors);}</code></pre><p>当A线程尝试获取这两个变量时，B线程已经修改了他们，A拿到了错误的结果，所以线程不安全。为了保护状态的一致性，要在单一的原子操作中更新相互关联的状态变量。  </p><h3 id="内部锁"><a href="#内部锁" class="headerlink" title="内部锁"></a>内部锁</h3><p>java提供了强制原子性的内置锁机制：synchronized块。一个synchronized块有两个部分：锁对象的引用，以及这个锁保护的代码块。其中<a href="https://blog.csdn.net/javazejian/article/details/72828483" target="_blank" rel="noopener">synchronized底层原理</a>为我们详细解释了这一关键字具体在字节码级别的实现。synchronized在方法上，拿到的对象就是对象本身，如果在静态方法上，则拿到该类的class字节码对象。每个java对象都可以隐式的扮演一个用于同步的锁的角色：这些内置的锁被称为内部锁或者监视器锁。执行线程进入synchronized块之前会自动获得锁；而无论正常退出还是抛出异常，线程都将释放锁资源。内部锁是互斥锁。</p><h3 id="可重入锁"><a href="#可重入锁" class="headerlink" title="可重入锁"></a>可重入锁</h3><p>当一个线程请求其他线程已经占有的锁时，请求线程将会被阻塞。然而内部锁是可重进入的，因此线程在试图获得它自己占有的锁时，请求会成功。重入的实现是为每个锁关联一个请求计数和一个占有它的线程。当计数器为0时，认为锁未被占用。线程请求一个未被占用的锁时，jvm将记录锁的占有者，并将请求数设置为1.如果同一线程在此请求这个锁，计数将递增；每次占用线程退出同步块，将递减。直到0时，锁释放。</p><h2 id="用锁来保护状态"><a href="#用锁来保护状态" class="headerlink" title="用锁来保护状态"></a>用锁来保护状态</h2><p>对于每个可被多个线程访问的可变状态变量，如果所有访问它的线程在执行时，都占有同一个锁，我们便称它是由锁保护的。</p>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_共享对象</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-gong-xiang-dui-xiang-1/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-gong-xiang-dui-xiang-1/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-共享对象"><a href="#并发编程-共享对象" class="headerlink" title="并发编程_共享对象"></a>并发编程_共享对象</h1><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>在以下的代码中，主线程和读线程两个线程共同访问变量ready和number。主线程启动读线程，然后把number设置为42，ready赋值为true，读线程一直循环直到发现ready变成true，然后打印出number的值，虽然看上去会输出42，实则不然，很有可能输出0，因为cpu缓存的缘故，甚至线程不会终止，因为缓存永远没有同步机制到内存，所以没能保证主线程写入ready和number对读线程可见。</p><pre><code>public class NoVisibility{    private static boolean ready;    private static int number;    public static class ReaderThread extends Thread{        public void run(){            while(!ready){                Thread.yield();            System.out.println(number);            }        }    }    public static void main(String[] args){        new ReaderThread().start();        number = 42;        ready = true;    }}</code></pre><p>这里甚至可能会出现奇怪的现象，NoVisibility可能会打印0，产生这种情况的原因便是指令发生了<strong>重排序</strong>。</p><h3 id="过期数据"><a href="#过期数据" class="headerlink" title="过期数据"></a>过期数据</h3><p>Novisibility演示了一种没有恰当同步程序，它能股引起意外的后果：过期数据。当线程检查ready变量时，它可能看到一个过期的值。除非每一次访问变量都是同步的，否则很可能得到变量的过期值。更坏的情况，过期既不会发生在全部变量上，也不会完全不出现：一个线程可能会得到一个变量最新的值，但是也可能得到另一个变量先前写入的过期值。<br>&emsp;&emsp;以下代码并不是线程安全的，因为get和set都访问了value域，却没有进行同步。在众多危害中，以下情况对过期数据尤为敏感：如果线程调用了set，而另一个线程此时正在调用get，他可能就看不到更新的数据了。<br>&emsp;&emsp;我们可以通过同步化getter和setter，使以下代码变为线程安全。</p><p><strong>非线程安全的可变整数访问器</strong></p><pre><code>public class MutableInteger{    private int value;    public int get(){        return value;    }    public void set(int value){        this.value = value;    }}</code></pre><p><strong>线程安全的可变整数访问器</strong></p><pre><code>public class SynchronizedInteger{    private int value;    public synchronized int get(){        return value;    }    public synchronized void set(int value){        this.value = value;    }}</code></pre><h3 id="非原子的64位操作"><a href="#非原子的64位操作" class="headerlink" title="非原子的64位操作"></a>非原子的64位操作</h3><p>&emsp;&emsp;当一个线程在没有同步的情况下读取变量，他可能会得到一个过期值。但是至少它可以看到某个线程在那里设定的一个真实数值，而不是一个凭空而来的值。这样的安全保证被称为是最低的安全性。<br>&emsp;&emsp;最低的安全性应用于所有的变量，除了一个例外：没有声明为volatile的64位数值变量（double和long）。java存储模型要求获取和存储操作都为原子的，但是对于非volatile的long和double变量，JVM允许将64位读或写划分为两个32位的操作。如果读和写发生在不同的线程，这种情况读取一个非volatile类型long就可能会出现得到一个值的高32位和另一个值的低32位。因此，即使你并不关心过期数据，但仅仅在多线程程序中使用共享的、可变的long 和 double变量也可能是不安全的，除非将它们声明为volatile类型，或者用锁保护。</p><h3 id="锁和可见性"><a href="#锁和可见性" class="headerlink" title="锁和可见性"></a>锁和可见性</h3><p>&emsp;&emsp;内置锁可以用来确保一个线程以某种可预见的方式看到另一个线程的影响。当A执行执行一个同步块时，线程B也随后进入了同一个锁监视的同步块中，这时就可以保证，在锁释放之前对A可见的变量值，B获得锁之后同样是可见的。换句话说，当B执行到与A相同的锁监视的同步块，A在同步块之中或之前所做的每一件事，对B都是可见的，如果没有同步，就没有这样的保证。<br>&emsp;&emsp;<strong>锁不仅仅是关于同步与互斥的，也是关于内存可见的。为了保证所有线程都能够看到共享的、可变变量的最新值，读取和写入线程必须使用公共的锁同步。</strong></p><h3 id="Volatile变量"><a href="#Volatile变量" class="headerlink" title="Volatile变量"></a>Volatile变量</h3><p>&emsp;&emsp;Java语言也提供了其他的选择，即一种同步的弱形式：volatile变量。它确保对一个变量的更新以可预见的方式告知其他线程。当域声明为volatile类型后，编译器与运行时会监视这个变量：它是共享的，而且对它的操作不会与其他的内存操作一起被重排序。volatile变量不会缓存在寄存器或者缓存在对其他处理器隐藏的地方。读一个volatile类型的变量时，总会返回由某一个线程写入的最新值。<br>&emsp;&emsp;<strong>只有当volatile变量能够简化实现和同步策略的验证时，才使用它们。当验证正确性必须推断可见性问题时，应该避免使用volatile变量。正确使用volatile变量的方式包括：用于确保它们所引用的对象状态的可见性，或者用于标志重要的生命周期事件的发生</strong>  </p><pre><code>volatile boolean sleep;while(sleep){    doSomething();}</code></pre><p>&emsp;&emsp;volatile变量固然方便，但存在限制，比如a++ 这种操作便不是原子化，除非你能保证只有一个线程对变量执行写操作<strong>加锁可以保证原子性，可见性，但volatile只能保证可见性.</strong><br>&emsp;&emsp;只有满足了下面所有标准后，你才能使用volatile变量：</p><ul><li>写入变量并不依赖变量的当前值：或者能确保只有单一线程修改变量的值；</li><li>变量不需要与其他的状态变量共同参与不变约束；</li><li>而且，访问变量时，没有其他的原因需要加锁。<h2 id="发布和逸出"><a href="#发布和逸出" class="headerlink" title="发布和逸出"></a>发布和逸出</h2>发布一个对象的意思是使它能够被当前范围之外的代码所使用。比如将一个引用存储到其他代码可以访问的地方，在一个非私有的方法中返回这个引用，也可以把它传递到其他类的方法中。在很多情况下，我们需要确保对象以及他们的内部状态不被暴露。在另外一些情况下，为了正当的使用目的，我们又的确希望发布一个对象，但是用线程安全的方法完成这些工作时，可能需要同步。如果变量发布内部状态，就可能危及到线程安全。一个对象在尚未准备好时就将它发布，这种情况称为逸出。<h2 id="线程封闭"><a href="#线程封闭" class="headerlink" title="线程封闭"></a>线程封闭</h2>&emsp;&emsp;访问共享的、可变的数据要求要求。一个可以避免同步的方式就是不共享数据。如果数据仅在单线程中访问，就不需要任何同步。线程封闭技术是实现线程安全的最简单方式之一。当对象封闭在一个线程中，这种做法会自动成为线程安全的，即使被封闭的对象本身并不是。<br>&emsp;&emsp;常见的使用线程限制的应用程序是应用池化的JDBC对象。JDBC规范并没有要求Connection对象是线程安全的。然而在典型的的服务器应用中，线程总是从池中获得一个Connection对象，并且用它处理一个单一的请求，最后将它归还。每个线程都会同步处理大多数请求，而且在Connection对象在归还前，池不会再将它分配给其他线程，因此，这种连接管理模式隐式地将Connection对象限制在处于请求处理期间的线程中。  <h3 id="Ad-hoc-线程限制"><a href="#Ad-hoc-线程限制" class="headerlink" title="Ad-hoc 线程限制"></a>Ad-hoc 线程限制</h3>&emsp;&emsp;<strong>Ad-hoc 线程限制</strong>是指维护线程限制性的任务全部落在实现上的这种情况。因为没有可见性修饰符与本地变量等语言特性协助将对象限制在目标线程上，所以这方式是非常容易出错的。事实上，对于像GUI应用中的可视化组件或者数据模型这些线程限制对象，对他们的引用通常是公用域。<h3 id="栈限制"><a href="#栈限制" class="headerlink" title="栈限制"></a>栈限制</h3>&emsp;&emsp;栈限制是线程限制的一种特例，在栈限制中，只能通过本地变量才可以触及对象。正如封装不变约束更容易被保持，本地变量使对象更容易被限制在线程本地中</li></ul><pre><code>public void test(){    int i;    int b;//这些变量都是线程私有的，存储在栈中，别的线程无法访问。}</code></pre><p>维护对象引用的栈限制，需要确保对象没有逸出。倘若我们发布了对象的引用，则该对象便会逸出。</p><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><p>&emsp;&emsp;一种维护线程限制的有效方式是使用ThreadLocal，它允许你将每个线程与持有数值的对象关联在一起。ThreadLocal提供了get与set访问器，为每个线程维护一份单独的拷贝。所以get总是返回当前线程执行通过set的最新值。<br>&emsp;&emsp;线程本地变量通常用于防止在基于可变单体或者全局变量的设计之中，出现不正确的共享</p><pre><code>private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;(){    public Connection initialValue(){        return DriverManager.getConnection(DB_URL);    }}public static Connection getConnection(){    return connectionHolder.ger();}</code></pre><p>&emsp;&emsp;这项技术还用于下面的情况：一个频繁执行的操作既需要像buffer的临时对象，同时还需要每次避免每次重新分配该对象。在5.0以前，Integer.toString()方法使用ThreadLocal存储一个12-byte的缓冲区来格式化结果，而不是使用共享的静态缓冲区，或者在每次调用前都分配一个新的缓冲区。**你可以将ThreadLocal看成一个map&lt;Thread,valeu&gt;但实际他不是，与线程相关的值存储在线程自身对象中，线程终止，这些值会被回收。</p><h2 id="不可变性"><a href="#不可变性" class="headerlink" title="不可变性"></a>不可变性</h2><p>使用final关键字可以使对象变的不可变，不可变对象永远线程安全。只有一下状态一个对象才不可变 </p><ul><li>他的状态创建后不能被修改。</li><li>所有域都是final类型。</li><li>它被正确的创建，没有逸出。<h3 id="final域"><a href="#final域" class="headerlink" title="final域"></a>final域</h3>&emsp;&emsp;final关键字源于C++的const机制，不过受到了很多限制，它对不可变性对象的创建提供了支持。final是不可被修改的（尽管对象的状态可变，这个对象仍然可被修改），final域使得确保初始化安全性成为可能，初始化安全性让不可变性对象不需要同步就能自由的被访问和共享。<h3 id="使用volatile发布不可变对象"><a href="#使用volatile发布不可变对象" class="headerlink" title="使用volatile发布不可变对象"></a>使用volatile发布不可变对象</h3></li></ul><pre><code>private volatile OneValueCache cache = new OneValueCche(null,null);public void service(){    cache = new OneValueCache(i,factors);}</code></pre><h3 id="安全的共享对象"><a href="#安全的共享对象" class="headerlink" title="安全的共享对象"></a>安全的共享对象</h3><p>在并发程序中，遵循使用和共享对象的策略为：</p><ul><li>线程限制：一个线程限制的对象，在通过限制在线程中，而被线程独占，且只能被占有它的线程修改。</li><li>共享只读：一个共享的只读对象，在没有同步的情况下，不会产生线程安全问题，共享只读对象包括可变对象与高效不可变对象。</li><li>共享线程安全：一个线程安全的对象在内部进行同步，所以其他线程无需额外同步，就可以通过公共接口访问它。</li><li>被守护的：一个被守护的对象只能通过特定的锁来访问，被守护的对象包括那些被线程安全对象封装的对象，和一直被特定的锁保护起来的已发布的对象。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_构建块</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-gou-jian-kuai-1/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-gou-jian-kuai-1/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-构建块"><a href="#并发编程-构建块" class="headerlink" title="并发编程_构建块"></a>并发编程_构建块</h1><h2 id="同步容器"><a href="#同步容器" class="headerlink" title="同步容器"></a>同步容器</h2><p>同步容器分为两部分，一个是vector和HashTable。他们早期是JDK的一部分：另一个是他们的同系容器，在JDK1.2才被加入的同步包装类。这些类是由Collections.synchronizedxxx工厂方法创建的。这些类通过封装他们的状态，并对每一个公共的方法进行同步而实现了线程安全。</p><h2 id="并发容器"><a href="#并发容器" class="headerlink" title="并发容器"></a>并发容器</h2><p>并发容器是为多线程而设计的，其中有代替Map的ConcurrentHashMap;读多写少的CopyOnWriteArrayList。同样新增了Queue和BlockingQueue。Queue用来临时保存正在等待被进一步处理的一系列元素。JDK提供了几种实现，包括一个传统的FIFO队列，ConcurrnetLinkedQueue;一个具有优先级的队列，PriorityQueue。BlockingQueue扩展了Queue，增加了可阻塞的插入和获取的操作。如果队列是空的，一个获取操作会阻塞到直到队列中存在元素；如果队列是满的，会阻塞到存在空间。阻塞队列对于生产者和消费者的设计非常有用。</p><h3 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h3><p>ConcurrentHashMap与其他容器一起，提供了不会抛出ConcurrentModificationException的迭代器，因此不需要再容器中加锁。但是对于整个Map进行操作的方法如size()和isEmpty,他们的语义在反映容器并发特性上被轻微的弱化了。因为size()的结果对于计算的时候可能已经过期，它仅仅是一个估算值。concurrentHashMap使用的是分离锁。</p><h3 id="对比ConcurrentHashMap与HashMap"><a href="#对比ConcurrentHashMap与HashMap" class="headerlink" title="对比ConcurrentHashMap与HashMap"></a>对比ConcurrentHashMap与HashMap</h3><h4 id="1、HashMap"><a href="#1、HashMap" class="headerlink" title="1、HashMap"></a>1、HashMap</h4><p>hashmap分为1.7与1.8两个版本其中1.7的版本如下图所示：<br><img src="https://i.loli.net/2019/05/08/5cd1d2be77958.jpg" alt="hashmap1.7结构图"><br>看看其实现<br><img src="https://i.loli.net/2019/05/08/5cd1d2bfd6aba.jpg" alt="hashmap实现">  </p><ul><li>初始化桶大小</li><li>桶最大值</li><li>默认负载因子</li><li>table真正存放数据的数组</li><li>Map存放数量的大小</li><li>桶大小</li><li>负载因子，可在初始化时显示指定  </li></ul><p>而在1.8的版本中增加了当链表达到8的长度时会转化为红黑树，而Entry改成了Node。在put方法中会判断结构是否是红黑树，如果是红黑树则按照红黑树的规则插入数据，判断是否大于阈值，大于则转为红黑树。</p><p>但是HashMap同样存在并发问题</p><pre><code>final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();for (int i = 0; i &lt; 1000; i++) {    new Thread(new Runnable() {        @Override        public void run() {            map.put(UUID.randomUUID().toString(), &quot;&quot;);        }    }).start();}</code></pre><p>HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。</p><h4 id="ConcurrentHashMap-1"><a href="#ConcurrentHashMap-1" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h4><p>1.7版本结构图：  </p><p><img src="https://i.loli.net/2019/05/08/5cd1d2c5ce95c.jpg" alt="ConcurrentHashMap结构图"><br>如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。<br>它的核心成员变量：</p><pre><code>/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;</code></pre><p>Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下：</p><pre><code> static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {       private static final long serialVersionUID = 2249069246763182397L;       // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶       transient volatile HashEntry&lt;K,V&gt;[] table;       transient int count;       transient int modCount;       transient int threshold;       final float loadFactor;}</code></pre><p>看看其中 HashEntry 的组成：<br><img src="https://i.loli.net/2019/05/08/5cd1d2c635c69.jpg" alt="HashEntry"><br>和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。</p><p>原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。  </p><p>下面也来看看核心的 put get 方法。<br>put 方法</p><pre><code>public V put(K key, V value) {    Segment&lt;K,V&gt; s;    if (value == null)        throw new NullPointerException();    int hash = hash(key);    int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject          // nonvolatile; recheck         (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //  in ensureSegment        s = ensureSegment(j);    return s.put(key, hash, value, false);}</code></pre><p>首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。  </p><pre><code>final V put(K key, int hash, V value, boolean onlyIfAbsent) {    HashEntry&lt;K,V&gt; node = tryLock() ? null :        scanAndLockForPut(key, hash, value);    V oldValue;    try {        HashEntry&lt;K,V&gt;[] tab = table;        int index = (tab.length - 1) &amp; hash;        HashEntry&lt;K,V&gt; first = entryAt(tab, index);        for (HashEntry&lt;K,V&gt; e = first;;) {            if (e != null) {                K k;                if ((k = e.key) == key ||                    (e.hash == hash &amp;&amp; key.equals(k))) {                    oldValue = e.value;                    if (!onlyIfAbsent) {                        e.value = value;                        ++modCount;                    }                    break;                }                e = e.next;            }            else {                if (node != null)                    node.setNext(first);                else                    node = new HashEntry&lt;K,V&gt;(hash, key, value, first);                int c = count + 1;                if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)                    rehash(node);                else                    setEntryAt(tab, index, node);                ++modCount;                count = c;                oldValue = null;                break;            }        }    } finally {        unlock();    }    return oldValue;}</code></pre><p>虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。</p><p>首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。  </p><p>在1.8版本中，则使用了synchronized+cas算法来进行锁的获取  </p>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_基础</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-ji-chu-2/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-ji-chu-2/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程基础"><a href="#并发编程基础" class="headerlink" title="并发编程基础"></a>并发编程基础</h1><hr><h2 id="进程与线程的区别与联系"><a href="#进程与线程的区别与联系" class="headerlink" title="进程与线程的区别与联系"></a>进程与线程的区别与联系</h2><p>进程是一个独立运行的程序，它有操作系统分配的内存空间，进程间的切换需要cpu进行空间地址的切换以及物理内存的交互。所以进程间的切换更加消耗资源。而线程是进程的组成基本单位，也是cpu调度的基本单位。</p><h2 id="使用多线程的好处？"><a href="#使用多线程的好处？" class="headerlink" title="使用多线程的好处？"></a>使用多线程的好处？</h2><ol><li>提高程序运行效率：多线程相当于在一个进程中在不同的环境中在同同一时刻共同执行。</li></ol><h2 id="线程的分类"><a href="#线程的分类" class="headerlink" title="线程的分类"></a>线程的分类</h2><h3 id="1、用户线程"><a href="#1、用户线程" class="headerlink" title="1、用户线程"></a>1、用户线程</h3><pre><code> 面试题：在一个进程中一定会有那个进程？ 答：主线程，进程靠主线程进行运行以及创建其他线程进行并行执行。</code></pre><h4 id="1、主线程"><a href="#1、主线程" class="headerlink" title="1、主线程"></a>1、主线程</h4><p>主线程时进程运行必须要有的线程，进程通过它来创建线程以及运行主要逻辑代码，主线程在main方法中运行，main方法运行完毕主线程结束。</p><h4 id="2、子线程"><a href="#2、子线程" class="headerlink" title="2、子线程"></a>2、子线程</h4><p>子线程是由主线程创建出来的线程，它有独立的运行逻辑与主线程互不干涉</p><h4 id="3、GC线程"><a href="#3、GC线程" class="headerlink" title="3、GC线程"></a>3、GC线程</h4><p>GC线程是java程序用于清理jvm内存空间的线程，该线程可以由用户手动调用，也可以由垃圾收集器创建对jvm虚拟机内存进行回收。</p><h3 id="2、守护线程-重点"><a href="#2、守护线程-重点" class="headerlink" title="2、守护线程(重点)"></a>2、守护线程(重点)</h3><h4 id="什么是守护线程（面试题）"><a href="#什么是守护线程（面试题）" class="headerlink" title="什么是守护线程（面试题）"></a>什么是守护线程（面试题）</h4><p>守护线程与主线程息息相关，如果主线程结束，其守护线程也随之死亡(GC线程)。主线程死亡时，gc线程必须死亡，所以gc也是守护线程。<br>实现一个守护线程：我们运行可以发现不管守护线程有没有执行完毕，都随着主线程执行完毕一起销毁  </p><pre><code>public class Thread004 {    public static void main(String[] args) {        Thread thread = new Thread(new Runnable() {            @Override            public void run() {                for(int i = 0; i &lt; 10; i++){                    try {                        Thread.sleep(300);                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                    System.out.println(&quot;i:&quot; + i);                }            }        });        //将该线程设置为守护线程        thread.setDaemon(true);        thread.start();        for (int i = 0; i &lt; 5; i++) {            try {                Thread.sleep(30);            } catch (InterruptedException e) {                e.printStackTrace();            }            System.out.println(&quot;主线程i:&quot; + i);        }        System.out.println(&quot;主线程执行完毕&quot;);    }}</code></pre><h2 id="线程的实现方式"><a href="#线程的实现方式" class="headerlink" title="线程的实现方式"></a>线程的实现方式</h2><h3 id="1、继承Thread类"><a href="#1、继承Thread类" class="headerlink" title="1、继承Thread类"></a>1、继承Thread类</h3><h4 id="Demo1：创建一个继承Thread类的子线程"><a href="#Demo1：创建一个继承Thread类的子线程" class="headerlink" title="Demo1：创建一个继承Thread类的子线程"></a>Demo1：创建一个继承Thread类的子线程</h4><pre><code>```java//继承Thread类.class ThreadDemo01 extends  Thread{    //run方法中写线程需要执行的代码    @Override    public void run() {        for(int i = 0; i &lt; 10 ; i++){            System.out.println(&quot;i:&quot;+i);        }    }}//什么是线程，线程是一条执行路径，每个线程互不影响//什么是多线程，多线程在一个进程中，有多条线程，并行执行。目的是为了提高程序的运行效率。public class Test01 {    public static void main(String[] args) {        //线程的几种分类，用户线程，守护线程        //用户线程：主线程、子线程、GC线程        //创建并启动线程        new ThreadDemo01().start();    }}```</code></pre><h3 id="2、实现Runnable接口（相对于继承方式更推荐这个）"><a href="#2、实现Runnable接口（相对于继承方式更推荐这个）" class="headerlink" title="2、实现Runnable接口（相对于继承方式更推荐这个）"></a>2、实现Runnable接口（相对于继承方式更推荐这个）</h3><p>相对于继承Thread类实现，由于Java只支持单继承，所以并不友好，推荐采用实现接口的方式，这样会有更好的扩展性。  </p><pre><code>class ThreadDemo02 implements Runnable{    @Override    public void run() {        for(int i = 0; i &lt; 10; i++){            System.out.println(&quot;i:&quot;+i);        }    }}public class Thread002 {    public static void main(String[] args) {        Thread thread = new Thread(new ThreadDemo02());        thread.start();    }}</code></pre><h3 id="3、使用匿名内部类"><a href="#3、使用匿名内部类" class="headerlink" title="3、使用匿名内部类"></a>3、使用匿名内部类</h3><p>使用匿名内部类的方式创建一个线程并运行 </p><pre><code>** * 使用内部类的方式创建线程 */public class Thread003 {    public static void main(String[] args) {        new Thread(new Runnable() {            @Override            public void run() {                for(int i = 0; i &lt; 10; i++){                    System.out.println(&quot;i:&quot; + i);                }            }        }).start();    }</code></pre><p>}</p><h3 id="4、使用线程池进行管理（最常用的方式）"><a href="#4、使用线程池进行管理（最常用的方式）" class="headerlink" title="4、使用线程池进行管理（最常用的方式）"></a>4、使用线程池进行管理（最常用的方式）</h3><h2 id="同步与异步的概念"><a href="#同步与异步的概念" class="headerlink" title="同步与异步的概念"></a>同步与异步的概念</h2><hr><p>同步表示代码从上往下进行执行，当一个方法阻塞，线程必须阻塞在那里等待结果的返回。<br>异步表示当一个方法需要等待返回结果，主线程到那里可以创建子线程去进行等待结果，当有结果产生时返回给主线程时，拿到结果执行相应的逻辑。没拿到结果则不需要等待，去进行其他任务。<br>常用的：Http请求分为同步与异步，Ajax的http请求便是异步的。</p><h2 id="多线程运行状态"><a href="#多线程运行状态" class="headerlink" title="多线程运行状态"></a>多线程运行状态</h2><ol><li>新建：new Thread();</li><li>就绪:thread.start();等待cpu分配时间片</li><li>运行:拿到执行权，线程运行</li><li>阻塞：遇到synchronized、wait进行阻塞</li><li>死亡：线程程序执行完毕，线程死亡，判断线程状态是否活着需要使用isAlive方法，如果是运行或者阻塞则返回true<br><img src="https://img-blog.csdnimg.cn/20181120173640764.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==,size_16,color_FFFFFF,t_70" alt="多线程运行状态"></li></ol><h2 id="join-方法的使用"><a href="#join-方法的使用" class="headerlink" title="join()方法的使用"></a>join()方法的使用</h2><p>join方法的是让其他线程变为等待，t1.join()//让其他线程变为等待，直到当前join方法执行完毕，才进行释放。Thread.join把指定线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了A线程的join()方法，直到A线程执行完毕，才会继续执行线程B  </p><pre><code>/** * join方法的使用示例 */public class Thread005 {    public static void main(String[] args) throws InterruptedException {        Thread t1 = new Thread(new Runnable() {            @Override            public void run() {                for (int i = 0; i &lt; 10; i++) {                    try {                        Thread.sleep(200);                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                    System.out.println(&quot;线程1在执行&quot; + i + &quot;次&quot;);                }            }        });        Thread t2 = new Thread(new Runnable() {            @Override            public void run() {                try {                    t1.join();                } catch (InterruptedException e) {                    e.printStackTrace();                }                for (int i = 0; i &lt; 10; i++) {                    System.out.println(&quot;线程2在执行&quot; + i + &quot;次&quot;);                }            }        });        t1.start();        t2.start();    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_线程之间的通讯</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-xian-cheng-zhi-jian-de-tong-xun-1/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-xian-cheng-zhi-jian-de-tong-xun-1/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-线程之间的通讯"><a href="#并发编程-线程之间的通讯" class="headerlink" title="并发编程_线程之间的通讯"></a>并发编程_线程之间的通讯</h1><h2 id="volatile与Synchronized的区别"><a href="#volatile与Synchronized的区别" class="headerlink" title="volatile与Synchronized的区别"></a>volatile与Synchronized的区别</h2><ul><li>volatile只能保持可见性，但不能保证原子性，synchronized既可以保证可见性又可以保证原子性</li><li>volatile禁止重排序，synchronized不禁止重排序。</li><li>volatile不需要加锁，比synchronized更加轻量级，并且不会阻塞线程。</li><li>volatile是变量修饰符，而synchronized是方法或者块的修饰符</li></ul><h2 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h2><p>编译器会对没有依赖关系的代码进行重排序<br>以下代码可能会发生重排序。</p><pre><code>int a;int b;</code></pre><h3 id="as-if-serial语义"><a href="#as-if-serial语义" class="headerlink" title="as-if-serial语义"></a>as-if-serial语义</h3><p>不管怎么去做重排序，其目的都是为了提高代码执行效率，但是不能影响正常结果。重排序只会在多线程的情况下预见，单线程不会。</p><pre><code>class RecordExample{    int a = 0;    boolean flag = false;    public void writer(){        a = 1;//1        flag = true;//2    }    public void reader(){        if(flag){//3            int i = a * a;//4        }    }}</code></pre><p>假如在writer()方法中发生了重排序，将使得reader得到错误的结果，此时flag=true;a还是0。</p><h2 id="wait和notify以及对象锁池"><a href="#wait和notify以及对象锁池" class="headerlink" title="wait和notify以及对象锁池"></a>wait和notify以及对象锁池</h2><h3 id="生产者与消费者"><a href="#生产者与消费者" class="headerlink" title="生产者与消费者"></a>生产者与消费者</h3><pre><code>/** * 生产者和消费者，wait()和notify()的实现 * @author ZGJ * @date 2017年6月22日 */public class Test1 {    private static Integer count = 0;    private static final Integer FULL = 10;    private static String LOCK = &quot;lock&quot;;    public static void main(String[] args) {        Test1 test1 = new Test1();        new Thread(test1.new Producer()).start();        new Thread(test1.new Consumer()).start();        new Thread(test1.new Producer()).start();        new Thread(test1.new Consumer()).start();        new Thread(test1.new Producer()).start();        new Thread(test1.new Consumer()).start();        new Thread(test1.new Producer()).start();        new Thread(test1.new Consumer()).start();    }    class Producer implements Runnable {        @Override        public void run() {            for (int i = 0; i &lt; 10; i++) {                try {                    Thread.sleep(3000);                } catch (Exception e) {                    e.printStackTrace();                }                synchronized (LOCK) {                    while (count == FULL) {                        try {                            LOCK.wait();                        } catch (Exception e) {                            e.printStackTrace();                        }                    }                    count++;                    System.out.println(Thread.currentThread().getName() + &quot;生产者生产，目前总共有&quot; + count);                    LOCK.notifyAll();                }            }        }    }    class Consumer implements Runnable {        @Override        public void run() {            for (int i = 0; i &lt; 10; i++) {                try {                    Thread.sleep(3000);                } catch (InterruptedException e) {                    e.printStackTrace();                }                synchronized (LOCK) {                    while (count == 0) {                        try {                            LOCK.wait();                        } catch (Exception e) {                        }                    }                    count--;                    System.out.println(Thread.currentThread().getName() + &quot;消费者消费，目前总共有&quot; + count);                    LOCK.notifyAll();                }            }        }    }}</code></pre><h3 id="wait与notify"><a href="#wait与notify" class="headerlink" title="wait与notify"></a>wait与notify</h3><p>1、为什么wait与notify需要定义在object中呢？<br>其实原理很简单，我们需要知道在java对象中，对象头里面含有锁标志，每个对象同时在虚拟机中对应一个监视器，但线程拿到该对象的锁标志，监视器会监视该线程的锁情况，所以在java中是用对象进行加锁，而所有对象又继承于Object类，所以这样定义在Object中，所有对象才会有唤醒和等待的方法。</p><h3 id="对象锁池"><a href="#对象锁池" class="headerlink" title="对象锁池"></a>对象锁池</h3><p>在Java中，每个对象都有两个池，锁(monitor)池和等待池  </p><ul><li>锁池:假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。</li><li>等待池:假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>并发编程_线程池原理</title>
      <link href="/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-xian-cheng-chi-yuan-li-1/"/>
      <url>/1024-xy.github.io/2019/11/01/bing-fa-bian-cheng-xian-cheng-chi-yuan-li-1/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程-线程池原理"><a href="#并发编程-线程池原理" class="headerlink" title="并发编程_线程池原理"></a>并发编程_线程池原理</h1><h2 id="阻塞队列与非阻塞队列"><a href="#阻塞队列与非阻塞队列" class="headerlink" title="阻塞队列与非阻塞队列"></a>阻塞队列与非阻塞队列</h2><ul><li>阻塞队列进行出队与入队操作会进行等待。</li><li>非阻塞队列不会进行阻塞<h3 id="ConcurrentLinkedQueue-非阻塞"><a href="#ConcurrentLinkedQueue-非阻塞" class="headerlink" title="ConcurrentLinkedQueue(非阻塞)"></a>ConcurrentLinkedQueue(非阻塞)</h3><h3 id="BlockingQueue-阻塞"><a href="#BlockingQueue-阻塞" class="headerlink" title="BlockingQueue(阻塞)"></a>BlockingQueue(阻塞)</h3>实现BlockingQueue接口的有ArrayBlockingQueue, DelayQueue, LinkedBlockingDeque, LinkedBlockingQueue, LinkedTransferQueue, PriorityBlockingQueue, SynchronousQueue，而这几种常见的阻塞队列也是在实际编程中会常用的，下面对这几种常见的阻塞队列进行说明：<blockquote><p>1.ArrayBlockingQueue  </p></blockquote></li></ul><p>ArrayBlockingQueue是由数组实现的有界阻塞队列。该队列命令元素FIFO（先进先出）。因此，对头元素时队列中存在时间最长的数据元素，而对尾数据则是当前队列最新的数据元素。ArrayBlockingQueue可作为“有界数据缓冲区”，生产者插入数据到队列容器中，并由消费者提取。ArrayBlockingQueue一旦创建，容量不能改变。<br>当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。</p><blockquote><p>2.LinkedBlockingQueue</p></blockquote><p>LinkedBlockingQueue是用链表实现的有界阻塞队列，同样满足FIFO的特性，与ArrayBlockingQueue相比起来具有更高的吞吐量，为了防止LinkedBlockingQueue容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE</p><blockquote><p>3.PriorityBlockingQueue</p></blockquote><p>PriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。</p><blockquote><p>4.SynchronousQueue</p></blockquote><p>SynchronousQueue每个插入操作必须等待另一个线程进行相应的删除操作，因此，SynchronousQueue实际上没有存储任何数据元素，因为只有线程在删除数据时，其他线程才能插入数据，同样的，如果当前有线程在插入数据时，线程才能删除数据。SynchronousQueue也可以通过构造器参数来为其指定公平性。</p><blockquote><p>5.LinkedTransferQueue</p></blockquote><p>LinkedTransferQueue是一个由链表数据结构构成的无界阻塞队列，由于该队列实现了TransferQueue接口，与其他阻塞队列相比主要有以下不同的方法：<br>transfer(E e)<br>如果当前有线程（消费者）正在调用take()方法或者可延时的poll()方法进行消费数据时，生产者线程可以调用transfer方法将数据传递给消费者线程。如果当前没有消费者线程的话，生产者线程就会将数据插入到队尾，直到有消费者能够进行消费才能退出；<br>tryTransfer(E e)<br>tryTransfer方法如果当前有消费者线程（调用take方法或者具有超时特性的poll方法）正在消费数据的话，该方法可以将数据立即传送给消费者线程，如果当前没有消费者线程消费数据的话，就立即返回false。因此，与transfer方法相比，transfer方法是必须等到有消费者线程消费数据时，生产者线程才能够返回。而tryTransfer方法能够立即返回结果退出。<br>tryTransfer(E e,long timeout,imeUnit unit)<br>与transfer基本功能一样，只是增加了超时特性，如果数据才规定的超时时间内没有消费者进行消费的话，就返回false。</p><h3 id="基于BlockingQueue的生产者消费者模式"><a href="#基于BlockingQueue的生产者消费者模式" class="headerlink" title="基于BlockingQueue的生产者消费者模式"></a>基于BlockingQueue的生产者消费者模式</h3><pre><code>package com.xxy.blockingqueue;import java.util.concurrent.BlockingQueue;import java.util.concurrent.LinkedBlockingDeque;import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;class Producer implements Runnable{    private BlockingQueue blockingQueue;    private AtomicInteger count = new AtomicInteger(0    );    private volatile  boolean flag = true            ;    Producer(BlockingQueue blockingQueue){        this.blockingQueue = blockingQueue;    }    public  void stop(){        this.flag = false;    }    @Override    public void run() {        System.out.println(&quot;生产者线程已经启动&quot;);        try {            while (flag){                String data = count.incrementAndGet() + &quot;&quot;;                boolean result = blockingQueue.offer(data,2, TimeUnit.SECONDS);                if(result){                    System.out.println(&quot;生产者存入队列成功&quot; + data);                }else {                    System.out.println(&quot;生产者存入队列失败&quot; + data);                }                Thread.sleep(1000);            }        } catch (InterruptedException e) {            e.printStackTrace();        }finally {            System.out.println(&quot;生产者线程结束&quot;);        }    }}class Consumer implements Runnable{    private BlockingQueue blockingQueue;    private volatile  boolean flag = true;    Consumer(BlockingQueue blockingQueue){        this.blockingQueue = blockingQueue;    }    @Override    public void run() {        System.out.println(&quot;消费者线程已经启动&quot;);        try {            while (flag){                String data = (String) blockingQueue.poll(2,TimeUnit.SECONDS);                if(data == null){                    System.out.println(&quot;消费超过2秒时间，没有获取到队列信息&quot;);                    flag = false;                    return;                }                System.out.println(&quot;消费者获取到data:&quot; + data);            }        }catch (Exception e){        }finally {            System.out.println(&quot;消费者线程结束&quot;);        }    }}public class Test004 {    public static void main(String[] args) throws InterruptedException {        BlockingQueue blockingQueue = new LinkedBlockingQueue(10);        Producer producer = new Producer(blockingQueue);        Consumer consumer = new Consumer(blockingQueue);        Thread t1 = new Thread(producer);        Thread t2 = new Thread(consumer);        t1.start();        t2.start();        Thread.sleep(1000 * 10);        producer.stop();    }}</code></pre><h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><p>java线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行的任务的程序，都可以使用线程池。在开发过程中，需要合理的使用线程池。</p><h3 id="线程池作用"><a href="#线程池作用" class="headerlink" title="线程池作用"></a>线程池作用</h3><ul><li>降低资源消耗：通过重复利用已创建的线程来降低线程创建和线程销毁造成的消耗。</li><li>提高效率：当任务到达，不必等到线程创建就能立即执行</li><li>方便管理：使用线程池，可以做到统一的调优和监控<h3 id="如何合理的配置线程池线程数？"><a href="#如何合理的配置线程池线程数？" class="headerlink" title="如何合理的配置线程池线程数？"></a>如何合理的配置线程池线程数？</h3>最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目<br>高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？<br>（1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换<br>（2）并发不高、任务执行时间长的业务要区分开看：<br>　　a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务<br>　　b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换<br>（3）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。<br>最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。  <h3 id="线程池的四种创建方式"><a href="#线程池的四种创建方式" class="headerlink" title="线程池的四种创建方式"></a>线程池的四种创建方式</h3>java通过Executor提供四种线程池：  </li><li>newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，灵活回收空闲线程，若无可回收，则新建线程。  </li><li>newFixThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。  </li><li>newScheduledThreadPool创建一个定长线程池，支持周期性任务执行。<br>newSingleThreadPool创建一个单线程化的线程池，它只会用唯一工作的工作线程来执行任务，按照顺序执行。</li></ul><h3 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h3><pre><code> /**     * Creates a new {@code ThreadPoolExecutor} with the given initial     * parameters and default thread factory and rejected execution handler.     * It may be more convenient to use one of the {@link Executors} factory     * methods instead of this general purpose constructor.     *     * @param corePoolSize the number of threads to keep in the pool, even     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set     * @param maximumPoolSize the maximum number of threads to allow in the     *        pool     * @param keepAliveTime when the number of threads is greater than     *        the core, this is the maximum time that excess idle threads     *        will wait for new tasks before terminating.     * @param unit the time unit for the {@code keepAliveTime} argument     * @param workQueue the queue to use for holding tasks before they are     *        executed.  This queue will hold only the {@code Runnable}     *        tasks submitted by the {@code execute} method.     * @throws IllegalArgumentException if one of the following holds:&lt;br&gt;     *         {@code corePoolSize &lt; 0}&lt;br&gt;     *         {@code keepAliveTime &lt; 0}&lt;br&gt;     *         {@code maximumPoolSize &lt;= 0}&lt;br&gt;     *         {@code maximumPoolSize &lt; corePoolSize}     * @throws NullPointerException if {@code workQueue} is null     */    public ThreadPoolExecutor(int corePoolSize,//核心线程数                              int maximumPoolSize,//最大线程数                              long keepAliveTime,//保持存活时间                              TimeUnit unit,//存放队列超时时间                              BlockingQueue&lt;Runnable&gt; workQueue) {//工作线程队列        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,             Executors.defaultThreadFactory(), defaultHandler);    }</code></pre><p><strong>步骤：</strong></p><ol><li>用户提交给线程池</li><li>判断是否大于核心线程数</li><li>如果大于核心线程数判断缓存队列是否已满，没满则存入队列，如果小于核心线程数，则创建线程执行任务。<br>具体原理如下：<br><img src="https://i.loli.net/2019/10/28/5v3zinyGOZ1hwrd.png" alt="线程池原理.png"></li></ol><p><strong>核心线程数与最大核心线程数的区别：</strong><br>核心线程数表示最大运行线程数，最大线程数表示最多可以创建多少个线程。<br>核心线程数只能小于等于最大线程数</p>]]></content>
      
      
      <categories>
          
          <category> 并发编程 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
